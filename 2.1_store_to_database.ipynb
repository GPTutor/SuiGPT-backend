{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3ddeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ea8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_move_files(directory):\n",
    "    move_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".move\"):\n",
    "                move_files.append(os.path.join(root, file))\n",
    "    return move_files\n",
    "\n",
    "\n",
    "# Use Sui's Examples\n",
    "directory = \"./sui/sui_programmability/examples/\"\n",
    "move_files = find_move_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29fdf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect to Elasticsearch Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37240/2498718443.py:8: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Elasticsearch Config\n",
    "es = Elasticsearch(\n",
    "    ['https://localhost:9200'],\n",
    "    http_auth=('elastic', config['ELASTIC_PASSWORD']),\n",
    "    verify_certs=True,\n",
    "    ca_certs='http_ca.crt'\n",
    ")\n",
    "\n",
    "# Check Connection\n",
    "if not es.ping():\n",
    "    raise ValueError(\"Fail to connect to Elasticsearch\")\n",
    "else:\n",
    "    print(\"Connect to Elasticsearch Success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da84eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"sui_gpt\"\n",
    "# Define all queries\n",
    "try:\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Clear index: Delete By Query\n",
    "    es.delete_by_query(index=index_name, body=query)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a0bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37240/2785200631.py:2: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.create(index=index_name, ignore=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'sui_gpt'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 建立索引\n",
    "es.indices.create(index=index_name, ignore=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395fb88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 24205.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for move_file in tqdm(move_files):\n",
    "    (\n",
    "        move_file\n",
    "    ) = \"./sui/sui_programmability/examples/fungible_tokens/sources/managed.move\"\n",
    "    with open(move_file, \"r\") as f:\n",
    "        d = (f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27727140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed4b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212ce8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                 | 0/68 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sui/sui_programmability/examples/nfts/sources/discount_coupon.moveac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(move_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     annotated_move \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(move_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mac\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     annotated_commented_move \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(move_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sui/sui_programmability/examples/nfts/sources/discount_coupon.moveac'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for move_file in tqdm(move_files):\n",
    "    # Read files\n",
    "    with open(move_file + \"a\", \"r\") as f:\n",
    "        source_move = f.read()\n",
    "    with open(move_file + \"a\", \"r\") as f:\n",
    "        annotated_move = f.read()\n",
    "    with open(move_file + \"ac\", \"r\") as f:\n",
    "        annotated_commented_move = f.read()\n",
    "    with open(move_file + \".summary\", \"r\") as f:\n",
    "        code_summary = f.read()\n",
    "    with open(move_file + \".title\", \"r\") as f:\n",
    "        code_title = f.read()\n",
    "\n",
    "    # create doc\n",
    "    doc = {\n",
    "        \"source_move\": source_move,\n",
    "        \"annotated_move\": annotated_move,\n",
    "        \"annotated_commented_move\": annotated_commented_move,\n",
    "        \"code_summary\": code_summary,\n",
    "        \"code_title\": code_title\n",
    "    }\n",
    "\n",
    "    # 索引文檔\n",
    "    es.index(index=index_name, document=doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c926cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"A fungible coin name and symbol is Eason that I can manage to airdrop by a list of whitelists\"\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"more_like_this\": {\n",
    "            \"fields\": [\"code_summary\", \"code_title\"],\n",
    "            \"like\": instructions,\n",
    "            \"min_term_freq\": 1,\n",
    "            \"max_query_terms\": 12\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 執行 MLT 查詢\n",
    "results = es.search(index=index_name, body=query)\n",
    "\n",
    "\n",
    "# Assuming 'results' is the result obtained from querying Elasticsearch\n",
    "\n",
    "# Create a dictionary to store the extracted fields\n",
    "result_dict = {}\n",
    "\n",
    "# Iterate through each document in the Elasticsearch results\n",
    "for doc in results['hits']['hits']:\n",
    "    # Extract the 'code_title' field\n",
    "    title = doc['_source']['code_title']\n",
    "\n",
    "    # Extract other fields\n",
    "    source_move = doc['_source']['source_move']\n",
    "    annotated_move = doc['_source']['annotated_move']\n",
    "    annotated_commented_move = doc['_source']['annotated_commented_move']\n",
    "    code_summary = doc['_source']['code_summary']\n",
    "    \n",
    "    # Store the extracted field values in a dictionary\n",
    "    result_dict[title] = {\n",
    "        'source_move': source_move,\n",
    "        'annotated_move': annotated_move,\n",
    "        'annotated_commented_move': annotated_commented_move,\n",
    "        'code_summary': code_summary,\n",
    "        'code_title': title\n",
    "    }\n",
    "\n",
    "# Print the resulting dictionary\n",
    "\n",
    "# Take the top 3 items\n",
    "top_3_results = dict(list(result_dict.items())[:3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output = {\n",
    "    \"match_titles\": result_dict.keys(),\n",
    "    \"top3_match\": top_3_results.keys(),\n",
    "    \"top3_match\": top_3_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find managed fungible coin and airdrop NFT contract first! Fit our need!\n",
    "print(result_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba786b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
